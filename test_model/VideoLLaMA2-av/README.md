# VideoLLaMA2
## ğŸ› ï¸ Requirements and Installation
Basic Dependencies:

* Pytorch >= 2.2.0
* CUDA Version >= 11.8
* transformers == 4.42.3
* tokenizers == 0.19.1


**[Offline Mode]** Install VideoLLaMA2 as a Python package (better for direct use):
```bash
git clone https://github.com/DAMO-NLP-SG/VideoLLaMA2
cd VideoLLaMA2
git checkout audio_visual
pip install --upgrade pip  # enable PEP 660 support
pip install -e .
pip install flash-attn==2.5.8 --no-build-isolation
pip install opencv-python==4.5.5.64
apt-get update && apt-get install ffmpeg libsm6 libxext6  -y
# å¯èƒ½è¿˜éœ€è¦å®‰è£…decordä¹‹ç±»çš„åŒ…
```

### Audio-Visual Checkpoints
| Model Name     | Type | Audio Encoder | Language Decoder |
|:-------------------|:----------------|:----------------|:------------------|
| [VideoLLaMA2.1-7B-AV](https://huggingface.co/DAMO-NLP-SG/VideoLLaMA2.1-7B-AV)  | Chat | [Fine-tuned BEATs_iter3+(AS2M)(cpt2)](https://1drv.ms/u/s!AqeByhGUtINrgcpj8ujXH1YUtxooEg?e=E9Ncea) | [VideoLLaMA2.1-7B-16F](https://huggingface.co/DAMO-NLP-SG/VideoLLaMA2.1-7B-16F)  |



## Inference
- model checkpointsè‡ªåŠ¨ä»huggingfaceä¸‹è½½
- Run `python testmodel.py` è°ƒæ•´`--modal-type`å‚æ•°ä»¥æµ‹è¯•ä¸åŒæ¨¡æ€ä¸‹æ¨¡å‹è¡¨ç°ï¼ˆé»˜è®¤ä¸ºAVæ¨¡æ€ï¼‰
- åœ¨è¿è¡Œä¹‹å‰ï¼Œä¿®æ”¹video_base_dir(è§†é¢‘æ–‡ä»¶ç›®å½•)ï¼Œjson_file_path(QA_json)